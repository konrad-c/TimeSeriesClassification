import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import ultrafast_shapelets as shapelets
import pysax
import timeit
from functools import partial
import itertools

# Classification
from xgboost import XGBClassifier
from sklearn.svm import LinearSVC
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import cross_val_score, GridSearchCV

# START Data Read
gun_path_train = "UCRData/Gun_Point/Gun_Point_TRAIN"
gun_file_train = open(gun_path_train, 'r')
gun_path_test = "UCRData/Gun_Point/Gun_Point_TEST"
gun_file_test = open(gun_path_test, 'r')

# Create data arrays
label_train = []
T_train = []
label_test = []
T_test = []
# TRAIN
for line in gun_file_train:
    vals = line.replace("\n", "") .split(',')
    label_train.append(vals[0])
    T_train.append(vals[1:])
# TEST
for line in gun_file_test:
    vals = line.replace("\n", "") .split(',')
    label_test.append(vals[0])
    T_test.append(vals[1:])
gun_file_train.close()
gun_file_test.close()
del gun_path_train, gun_file_train, gun_path_test, gun_file_test, line, vals
# END Data Read

# Get numpy arrays
label_train = np.array(label_train).astype(np.float)
T_train = np.array(T_train).astype(np.float)

label_test = np.array(label_test).astype(np.float)
T_test = np.array(T_test).astype(np.float)

def shapelet_discovery(T_train, label_train, T_test, label_test, shapelet_num, approx=False, useSVC=True):
    # Train model on shapelets generated by TRAIN
    if approx:
        assert shapelet_num > 100, "Shapelet num must be greater than 100 for approx"
        T_train_features, T_shapelets = shapelets.motif_feature_approx(T_train,label_train,100,shapelet_num)
    else:
        T_train_features, T_shapelets = shapelets.ts_shapelet_features_univariate(T_train,shapelet_num)

    # Get feature distances from shapelets generated by TRAIN
    T_test_features = shapelets.ts_features_from_shapelets(T_test, T_train, np.array(T_shapelets))
    
    ### Classificaton with XGBoost
    model_xgb = XGBClassifier(n_estimators=100, max_depth=5)
    model_xgb.fit(T_train_features, label_train)
    
    ### Classification with SVM Classifier (SVC)
    model_svc = SVC(kernel="linear")
    model_svc.fit(T_train_features, label_train)
    
    ### Decide on model:
    if useSVC:
        model = model_svc # model_xgb
    else:
        model = model_xgb
    
    predictions = model.predict(T_test_features)
    print("Error (Test):",np.where(np.array(predictions)-np.array(label_test) != 0)[0].shape[0]/float(len(predictions)))
    print("Avg Cross Validation Accuracy (Test):",np.mean(cross_val_score(model, T_test_features,label_test, cv=10)))

def plot_results(T_train, label_train, T_test, label_test):
    """
    Run timer and plot time complexity
    """
    shapelet_nums = np.arange(10,200,10)#np.arange(500,2001,500)
    pruned_nums = [-1]#np.arange(5,51,5)
    raw_num = []
    p_num = []
    time_arr = []
    accuracy = []
    out_file = open("out_results.csv","w+")
    out_file.write("raw_shapelet_num,pruned_shapelet_num,time,accuracy\n")
    for j in pruned_nums:
        for i in shapelet_nums:
            # Check time
            before = timeit.time.time()
            #T_train_features, T_shapelets = shapelets.motif_feature_approx(T_train, label_train, j, i, reduced=True)
            T_train_features, T_shapelets = shapelets.ts_shapelet_features_univariate(T_train, i)
            # Check accuracy
            T_test_features = shapelets.ts_features_from_shapelets(T_test, T_train, np.array(T_shapelets))
            # Normalize data
            scaler = StandardScaler().fit(T_train_features)
            T_train_features = scaler.transform(T_train_features)
            T_test_features = scaler.transform(T_test_features)
            # Predict
            model_svc = LinearSVC()
            params = {'C':(2,4,8,16,32,64,128,256,512,1024)}
            clf = GridSearchCV(model_svc, params)
            clf.fit(T_train_features, label_train)
            after = timeit.time.time()
            predictions = clf.predict(T_test_features)
            # Save values
            acc = np.round(1 - (np.where(np.array(predictions)-np.array(label_test) != 0)[0].shape[0]/float(len(predictions))), decimals=5)
            t = np.round(after - before, decimals=2)
            print(j,i,"ran in",t)
            print("Accuracy ( r=",j,"p=",i,"):",acc)
            raw_num.append(i)
            p_num.append(j)
            time_arr.append(t)
            accuracy.append(acc)
            out_file.write(str(i)+","+str(j)+","+str(t)+","+str(acc)+"\n")
    out_file.close()
    plt.plot(raw_num, time_arr, 'bo')
    plt.show()
    plt.plot(raw_num, accuracy, 'g^')
    plt.show()

def SAX_NN(T_train, label_train, T_test, label_test, reduced=False):
    # Create SAX encoding model
    sax_model = pysax.SAXModel(alphabet="ABCDEFGHIJKLMNOPQ")
    
    # Create SAX representatiosn of time series'
    sax_rep = np.array([sax_model.symbolize(s) for s in T_train])
    sax_rep_test = np.array([sax_model.symbolize(s) for s in T_test])
    
    if reduced:
        sax_rep = np.array([''.join(ch for ch, _ in itertools.groupby(s)) for s in sax_rep])
        sax_rep_strings = np.array(["".join(s) for s in sax_rep])
        sax_rep_test = np.array([''.join(ch for ch, _ in itertools.groupby(s)) for s in sax_rep_test])
        sax_rep_strings_test = np.array(["".join(s) for s in sax_rep_test])
    else:
        sax_rep_strings = np.array(["".join(s) for s in sax_rep])
        sax_rep_strings_test = np.array(["".join(s) for s in sax_rep_test])
    
    # TEST nearest neighbour on TEST set:
    accuracy = 0
    for i in range(0, len(T_test)):
        word = sax_rep_strings_test[i]
        min_dist_index = np.argmin(np.array([sax_model.symbol_distance(word, w) for w in sax_rep_strings]))
        min_dist = sax_model.symbol_distance(word, sax_rep_strings[min_dist_index])
        classification = label_train[min_dist_index]
        if(classification == label_test[i]):
            accuracy = accuracy + 1
        #print(i,":",word,"matched with",sax_rep_strings[min_dist_index],"dist :",min_dist, " CLASSIFICATION: predicted",classification,"real",label_test[i])
    print("Total Error :",1.0 - (float(accuracy)/float(len(T_test))))
    print("Total Accuracy :",(float(accuracy)/float(len(T_test))))

plot_results(T_train, label_train, T_test, label_test)
#shapelet_discovery(T_train, label_train, T_test, label_test, 500, approx=False, useSVC=True)
#SAX_NN(T_train, label_train, T_test, label_test, reduced=False)
#SAX_NN(T_train, label_train, T_test, label_test, reduced=True)
