import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import ultrafast_shapelets as shapelets
import pysax
import timeit
from functools import partial
import itertools

# Classification
from xgboost import XGBClassifier
from sklearn.svm import LinearSVC
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import cross_val_score, GridSearchCV

# START Data Read
gun_path_train = "UCRData/Gun_Point/Gun_Point_TRAIN"
gun_file_train = open(gun_path_train, 'r')
gun_path_test = "UCRData/Gun_Point/Gun_Point_TEST"
gun_file_test = open(gun_path_test, 'r')

# Create data arrays
label_train = []
T_train = []
label_test = []
T_test = []
# TRAIN
for line in gun_file_train:
    vals = line.replace("\n", "") .split(',')
    label_train.append(vals[0])
    T_train.append(vals[1:])
# TEST
for line in gun_file_test:
    vals = line.replace("\n", "") .split(',')
    label_test.append(vals[0])
    T_test.append(vals[1:])
gun_file_train.close()
gun_file_test.close()
del gun_path_train, gun_file_train, gun_path_test, gun_file_test, line, vals
# END Data Read

# Get numpy arrays
label_train = np.array(label_train).astype(np.float)
T_train = np.array(T_train).astype(np.float)

label_test = np.array(label_test).astype(np.float)
T_test = np.array(T_test).astype(np.float)

def shapelet_discovery(T_train, label_train, T_test, label_test, shapelet_num, approx=False, useSVC=True):
    # Train model on shapelets generated by TRAIN
    if approx:
        assert shapelet_num > 100, "Shapelet num must be greater than 100 for approx"
        T_train_features, T_shapelets = shapelets.motif_feature_approx(T_train,label_train,100,shapelet_num)
    else:
        T_train_features, T_shapelets = shapelets.ts_shapelet_features_univariate(T_train,shapelet_num)

    # Get feature distances from shapelets generated by TRAIN
    T_test_features = shapelets.ts_features_from_shapelets(T_test, T_train, np.array(T_shapelets))
    
    ### Classificaton with XGBoost
    model_xgb = XGBClassifier(n_estimators=100, max_depth=5)
    model_xgb.fit(T_train_features, label_train)
    
    ### Classification with SVM Classifier (SVC)
    model_svc = SVC(kernel="linear")
    model_svc.fit(T_train_features, label_train)
    
    ### Decide on model:
    if useSVC:
        model = model_svc # model_xgb
    else:
        model = model_xgb
    
    predictions = model.predict(T_test_features)
    print("Error (Test):",np.where(np.array(predictions)-np.array(label_test) != 0)[0].shape[0]/float(len(predictions)))
    print("Avg Cross Validation Accuracy (Test):",np.mean(cross_val_score(model, T_test_features,label_test, cv=10)))

def plot_results(T_train, label_train, T_test, label_test):
    """
    Run timer and plot time complexity
    """
    shapelet_nums = np.arange(400,601,50)
    x = []
    time = []
    accuracy = []
    for i in shapelet_nums:
        # Check time
        before = timeit.time.time()
        T_train_features, T_shapelets = shapelets.motif_feature_approx(T_train, label_train, 50, i, reduced=True)
        #T_train_features, T_shapelets = shapelets.ts_shapelet_features_univariate(T_train, i)
        # Check accuracy
        T_test_features = shapelets.ts_features_from_shapelets(T_test, T_train, np.array(T_shapelets))
        # Normalize data
        scaler = StandardScaler().fit(T_train_features)
        T_train_features = scaler.transform(T_train_features)
        T_test_features = scaler.transform(T_test_features)
        # Predict
        model_svc = LinearSVC()
        params = {'C':(2,4,8,16,32,64,128,256,512,1024)}
        clf = GridSearchCV(model_svc, params)
        clf.fit(T_train_features, label_train)
        after = timeit.time.time()
        predictions = clf.predict(T_test_features)
        # Save values
        acc = np.round(1 - (np.where(np.array(predictions)-np.array(label_test) != 0)[0].shape[0]/float(len(predictions))), decimals=5)
        t = np.round(after - before, decimals=2)
        print(i,"ran in",t)
        print("Accuracy ( p=",i,"):",acc)
        x.append(i)
        time.append(t)
        accuracy.append(acc)
    plt.plot(x, time, 'bo')
    plt.show()
    plt.plot(x, accuracy, 'g^')
    plt.show()

def SAX_NN(T_train, label_train, T_test, label_test, reduced=False):
    # Create SAX encoding model
    sax_model = pysax.SAXModel(alphabet="ABCDEFGHIJKLMNOPQ")
    
    # Create SAX representatiosn of time series'
    sax_rep = np.array([sax_model.symbolize(s) for s in T_train])
    sax_rep_test = np.array([sax_model.symbolize(s) for s in T_test])
    
    if reduced:
        sax_rep = np.array([''.join(ch for ch, _ in itertools.groupby(s)) for s in sax_rep])
        sax_rep_strings = np.array(["".join(s) for s in sax_rep])
        sax_rep_test = np.array([''.join(ch for ch, _ in itertools.groupby(s)) for s in sax_rep_test])
        sax_rep_strings_test = np.array(["".join(s) for s in sax_rep_test])
    else:
        sax_rep_strings = np.array(["".join(s) for s in sax_rep])
        sax_rep_strings_test = np.array(["".join(s) for s in sax_rep_test])
    
    # TEST nearest neighbour on TEST set:
    accuracy = 0
    for i in range(0, len(T_test)):
        word = sax_rep_strings_test[i]
        min_dist_index = np.argmin(np.array([sax_model.symbol_distance(word, w) for w in sax_rep_strings]))
        min_dist = sax_model.symbol_distance(word, sax_rep_strings[min_dist_index])
        classification = label_train[min_dist_index]
        if(classification == label_test[i]):
            accuracy = accuracy + 1
        #print(i,":",word,"matched with",sax_rep_strings[min_dist_index],"dist :",min_dist, " CLASSIFICATION: predicted",classification,"real",label_test[i])
    print("Total Error :",1.0 - (float(accuracy)/float(len(T_test))))
    print("Total Accuracy :",(float(accuracy)/float(len(T_test))))

plot_results(T_train, label_train, T_test, label_test)
#shapelet_discovery(T_train, label_train, T_test, label_test, 500, approx=False, useSVC=True)
#SAX_NN(T_train, label_train, T_test, label_test, reduced=False)
#SAX_NN(T_train, label_train, T_test, label_test, reduced=True)
