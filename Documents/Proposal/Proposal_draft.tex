\documentclass[10pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{float}
\newcommand\tab[1][1cm]{\hspace*{#1}}
\usepackage{graphicx}
\usepackage{scrextend}
\usepackage{wrapfig}
\usepackage{enumitem}
\author{Konrad Cybulski}
\title{k-Nearest Shapelets for Time Series Classification}
\begin{document}
\begin{titlepage}
    \begin{center}
        \vspace*{1cm}
        
        \LARGE
        \textbf{k-Nearest Shapelets for Time Series Classification}
        
        \vspace{4cm}
        
		\Large 
        
        \textbf{Konrad Cybulski}
        
        
        \LARGE
        \vspace{2cm}

        
        
        \vfill
        
        
        
        Research Proposal \\
        FIT2082 Research Project
        
        
        \includegraphics[width=0.4\textwidth]{Images/monash_emblem.jpg}
              
        
        \large
        Faculty of Information Technology\\
        Monash University\\
        Australia\\
        10/08/2017
        
    \end{center}
\end{titlepage}

\pagebreak
\tableofcontents
\pagebreak

\section{Introduction} 

In the field of time series classification, Nearest Neighbour (NN)
classification models provide highly accurate methods for binary and multiclass classification.
However due to the large time complexity associated with NN models, an increasingly common technique involves Nearest Centroid approximations of NN.
A recent promising concept in this field are time series shapelets which have shown to be orders of magnitude faster than NN classifiers with comparable accuracy.
\\
As noted by Rakthanmanon \& Keogh (2013), in comparison with NN, a "\textit{lazy} classifier", shapelets lead to \textit{eager} classifiers. 
Current shapelet discovery methods (and models utilising shapelets for classification) aim to determine class representative shapelets.
Resultantly there is some amount of information loss when a single shapelet is used as a class identifier [6,7].
\\
This research aims to utilise sequential aggregate approximation (SAX) for shapelet distance approximation to aid randomly generated shapelet pruning. 
This research is based on the principle proposed by Wisstuba et al. that a class representative shapelet will occur often in a dataset.
Thus the random generation of shapelets will produce class representative shapelets for a given dataset.
The algorithm designed by Wisstuba et al. converts minimum shapelet distance to time series data into a transformed feature set. 
This transformation involves calculating minimum subsequence distance which is infeasible for large datasets or large numbers of shapelets (which invariably produce more accurate results).
Using approximate distance measures to determine class representative shapelets will thus reduce the necessary computation to attain accurate prediction from the \textit{ultra-fast shapelet} algorithm.

\section{Background}
\subsection{Shapelets}
Shapelets are in ever increasing use in the field of time series classification.
While NN classification models are still renowned for their high accuracy despite their simplistic nature, shapelets offer not only competitive classification but provide human-readable results [1, 2, 3, 4]. 
Shapelets aim to determine a key subsequence within a class of classifiable time series' which is representative of that class [3].
They have been shown to be robust to noise due to the shapelet defining a common subsequence in a given class.
Additionally being robust to time series length given they represent a common subsequence, length normalization may be omitted in favour of more information rich data.
The use of shapelets in classificaton models involves the creation of decision-trees using  the most likely fitting shapelet as a feature [1,2,3].
As a result, in \textit{n}-class classification, the resulting number of extracted features will be \textit{n}.
These shapelets are produced by maximising occurrences of a subsequence (shapelet) in a given class and minimising occurrences of the same subsequence in other classes.
However there still exists a level of information loss due to this, exemplified in cases where multiple shapelets may define a class to a greater extent than a single subsequence [6,7].
\\

\subsection{Distance Measure}
Euclidean distance is one of the most common distance measures for both NN classification as well as shapelet based classification methods [1,2,3,4].
Dynamic Time Warping (DTW) has in recent years been shown in a number of cases to improve classification accuracy in NN models [4,5].
The use of shapelets in time series classification has utilised Euclidean distance measures for a large area of research [1,2,3] however DTW as a measure of shapelet subsequence distance has been shown to outperform 1-NN-DTW and existing shapelet models in a number of real world and UCR datasets [4].
\\
In research that uses euclidean distance measures, shapelets are still competitive with regard to classification accuracy [1,2,3,4,6] and using certain techniques, orders of magnitude faster than traditional NN and exhaustive shapelet search (ES) [1,7].
Despite DTW being a more accurate distance measure in NN classification, techniques involving top \textit{k} shapelets [6,7] lower error associated with euclidean distance measures.
 


\section{Method}

\section{Preliminary  Results}

\section{Further Work} 

\pagebreak
\begin{thebibliography}{9}

\bibitem{1}
Rakthanmanon, T., \& Keogh, E. (2013, May). Fast shapelets: A scalable algorithm for discovering time series shapelets. In \textit{Proceedings of the 2013 SIAM International Conference on Data Mining} (pp. 668-676). Society for Industrial and Applied Mathematics.
Retrieved from http://epubs.siam.org/doi/pdf/10.1137/1.9781611972832.74 

\bibitem{2}
Raza, A., \& Kramer, S. (2017). Ensembles of Randomized Time Series Shapelets Provide Improved Accuracy while Reducing Computational Costs. \textit{arXiv preprint arXiv}:1702.06712.

\bibitem{3}
Ye, L., \& Keogh, E. (2011). Time series shapelets: a novel technique that allows accurate, interpretable and fast classification. \textit{Data mining and knowledge discovery}, 22(1), 149-182.

\bibitem{4}
Shah, M., Grabocka, J., Schilling, N., Wistuba, M., \& Schmidt-Thieme, L. (2016, March). Learning DTW-shapelets for time-series classification. In \textit{Proceedings of the 3rd IKDD Conference on Data Science}, 2016 (p. 3). ACM.

\bibitem{5}
Petitjean, F., Forestier, G., Webb, G. I., Nicholson, A. E., Chen, Y., \& Keogh, E. (2016). Faster and more accurate classification of time series by exploiting a novel dynamic time warping averaging algorithm. \textit{Knowledge and Information Systems}, 47(1), 1-26.

\bibitem{6}
Lines, J., Davis, L. M., Hills, J., \& Bagnall, A. (2012, August). A shapelet transform for time series classification. In \textit{Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining} (pp. 289-297). ACM.\\
Available at \textbf{https://ueaeprints.uea.ac.uk/40201/1/LinesKDD2012.pdf}

\bibitem{7}
Wistuba, M., Grabocka, J., \& Schmidt-Thieme, L. (2015). Ultra-fast shapelets for time series classification. \textit{arXiv preprint} arXiv:1503.05018.

\end{thebibliography}

\end{document}
